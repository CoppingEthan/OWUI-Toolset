# ═══════════════════════════════════════════════════════════════
# OWUI Toolset V2 - Configuration
# Copy this file to .env and fill in your values:
#   cp .env.example .env
#
# LLM API keys and tool service URLs (OpenAI, Anthropic, Ollama,
# Tavily, ComfyUI) are configured as pipeline valves in Open WebUI
# on owui-pipe.py, not here.
# ═══════════════════════════════════════════════════════════════

# ── Server ────────────────────────────────────────────────────
PORT=3000
HOST=0.0.0.0
DASHBOARD_PORT=3001
PUBLIC_DOMAIN=http://localhost:3000

# ── Authentication ────────────────────────────────────────────
API_SECRET_KEY=your-secret-key-here
DASHBOARD_USERNAME=admin
DASHBOARD_PASSWORD=change_this_password

# ── Security ──────────────────────────────────────────────────
# Comma-separated list of allowed OWUI instance IPs/CIDRs
# Use * to allow all (default)
ALLOWED_OWUI_INSTANCES=*
ENABLE_CORS=false

# ── Database ──────────────────────────────────────────────────
# DATABASE_PATH=data/metrics.db

# ── Tool Services ─────────────────────────────────────────────
# Docling server URL for PDF/DOCX extraction (read server-side)
# DOCLING_BASE_URL=

# ── Anthropic Settings ────────────────────────────────────────
# Max output tokens for Anthropic models
# ANTHROPIC_MAX_TOKENS=8192

# ── Limits ────────────────────────────────────────────────────
# MAX_TOOL_ITERATIONS=5
# MAX_MEMORY_CHARS=2000
# Max input tokens per request (0 = unlimited, ~4 chars/token estimate)
# Trims oldest messages to stay within budget. Recommended: 128000
# MAX_INPUT_TOKENS=0
# Max tokens per user message and per file (0 = unlimited, ~3.2 chars/token)
# Latest message: limit scales with file count (8k + 8k per attached file)
# Older messages: replaced with a notice to prevent history bloat
# Also caps CEE-extracted file content at /process (first/last halves preserved)
# MAX_USER_MESSAGE_TOKENS=8192

# ── Compaction ───────────────────────────────────────────────
# Token threshold to trigger conversation compaction (0 = disabled)
# When estimated input tokens exceed this, older messages are summarized
# COMPACTION_TOKEN_THRESHOLD=65536

# Max output tokens for the compaction summary (500-2000 recommended)
# Higher = more detailed summaries for complex/technical conversations
# COMPACTION_MAX_SUMMARY_TOKENS=1024

# ── Dashboard ────────────────────────────────────────────────
# Allow one-click upgrade from the dashboard (runs deploy.sh)
# ALLOW_REMOTE_UPGRADE=false

# ── Debug ─────────────────────────────────────────────────────
# DEBUG_MODE=false
